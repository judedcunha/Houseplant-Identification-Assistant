{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Houseplant Identification Assistant\n",
    "\n",
    "This notebook implements a machine learning-based application that helps identify common houseplants from images and provides basic care recommendations. The application uses computer vision techniques to classify houseplant images and displays relevant care information for the identified plants.\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Data Preparation](#data)\n",
    "3. [Model Development](#model)\n",
    "4. [Training the Model](#training)\n",
    "5. [Inference and Evaluation](#inference)\n",
    "6. [Care Recommendations](#care)\n",
    "7. [Interactive Interface with Gradio](#interface)\n",
    "\n",
    "Let's begin by setting up our environment and installing the necessary dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation <a id=\"setup\"></a>\n",
    "\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.28.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.10.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.10.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.11.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.11.7)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.15.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\firec\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision tqdm numpy matplotlib pandas pillow gradio scikit-learn transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gradio as gr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation <a id=\"data\"></a>\n",
    "\n",
    "We'll now define our dataset of common houseplants. For the purposes of this notebook, we'll create a database with information about 20 common houseplant species and their care requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of common houseplant species\n",
    "COMMON_HOUSEPLANTS = [\n",
    "    \"Monstera deliciosa\",        # Swiss Cheese Plant\n",
    "    \"Ficus lyrata\",              # Fiddle Leaf Fig\n",
    "    \"Sansevieria trifasciata\",   # Snake Plant\n",
    "    \"Chlorophytum comosum\",      # Spider Plant\n",
    "    \"Epipremnum aureum\",         # Pothos\n",
    "    \"Spathiphyllum wallisii\",    # Peace Lily\n",
    "    \"Zamioculcas zamiifolia\",    # ZZ Plant\n",
    "    \"Dracaena marginata\",        # Dragon Tree\n",
    "    \"Calathea makoyana\",         # Peacock Plant\n",
    "    \"Pilea peperomioides\",       # Chinese Money Plant\n",
    "    \"Philodendron bipinnatifidum\", # Split-leaf Philodendron\n",
    "    \"Aloe vera\",                 # Aloe Vera\n",
    "    \"Ficus elastica\",            # Rubber Plant\n",
    "    \"Maranta leuconeura\",        # Prayer Plant\n",
    "    \"Aglaonema commutatum\",      # Chinese Evergreen\n",
    "    \"Peperomia obtusifolia\",     # Baby Rubber Plant\n",
    "    \"Anthurium andraeanum\",      # Flamingo Flower\n",
    "    \"Schlumbergera bridgesii\",   # Christmas Cactus\n",
    "    \"Crassula ovata\",            # Jade Plant\n",
    "    \"Aspidistra elatior\"         # Cast Iron Plant\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create care information database\n",
    "care_database = {\n",
    "  \"Monstera deliciosa\": {\n",
    "    \"common_name\": \"Swiss Cheese Plant\",\n",
    "    \"light\": \"Bright indirect light. Avoid direct sunlight which can burn the leaves.\",\n",
    "    \"water\": \"Allow top 2-3 inches of soil to dry out between waterings. Water less in winter.\",\n",
    "    \"soil\": \"Well-draining potting mix with some peat and perlite.\",\n",
    "    \"temperature\": \"65-85°F (18-29°C). Keep away from cold drafts.\",\n",
    "    \"humidity\": \"Prefers moderate to high humidity. Regular misting is beneficial.\",\n",
    "    \"fertilizer\": \"Feed monthly during growing season with balanced houseplant fertilizer.\",\n",
    "    \"common_issues\": \"Brown leaf tips (low humidity), yellow leaves (overwatering), lack of fenestration (insufficient light).\",\n",
    "    \"toxicity\": \"Toxic to pets if ingested. Contains calcium oxalate crystals.\"\n",
    "  },\n",
    "  \"Ficus lyrata\": {\n",
    "    \"common_name\": \"Fiddle Leaf Fig\",\n",
    "    \"light\": \"Bright indirect light. Some direct morning sun is beneficial.\",\n",
    "    \"water\": \"Water when top inch of soil is dry. Ensure thorough drainage.\",\n",
    "    \"soil\": \"Well-draining potting mix with peat and perlite.\",\n",
    "    \"temperature\": \"60-75°F (15-24°C). Avoid temperature fluctuations.\",\n",
    "    \"humidity\": \"Moderate humidity, around 40-60%.\",\n",
    "    \"fertilizer\": \"Feed monthly in spring and summer with diluted houseplant fertilizer.\",\n",
    "    \"common_issues\": \"Brown spots (overwatering or bacterial infection), leaf drop (stress from relocation or temperature changes).\",\n",
    "    \"toxicity\": \"Mildly toxic to pets and humans if ingested.\"\n",
    "  },\n",
    "  \"Sansevieria trifasciata\": {\n",
    "    \"common_name\": \"Snake Plant\",\n",
    "    \"light\": \"Adaptable to various light conditions from low light to bright indirect light.\",\n",
    "    \"water\": \"Allow soil to dry completely between waterings. Water sparingly in winter.\",\n",
    "    \"soil\": \"Well-draining, sandy soil mix.\",\n",
    "    \"temperature\": \"55-85°F (13-29°C). Can tolerate temperature fluctuations.\",\n",
    "    \"humidity\": \"Adaptable to various humidity levels, including dry air.\",\n",
    "    \"fertilizer\": \"Feed sparingly with cactus fertilizer during growing season.\",\n",
    "    \"common_issues\": \"Root rot (overwatering), brown tips (fluoride in water).\",\n",
    "    \"toxicity\": \"Mildly toxic to pets if ingested.\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Save the care database to a JSON file\n",
    "with open(\"data/care_database.json\", \"w\") as f:\n",
    "    json.dump(care_database, f, indent=2)\n",
    "\n",
    "print(f\"Created care database with {len(care_database)} plant species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n",
    "\n",
    "Now, let's define our dataset and image transformations for training, validation, and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and transformations\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# Create transformations for training and validation\n",
    "def create_transforms(is_training=True):\n",
    "    \"\"\"Create image transformation pipelines for training and validation sets.\"\"\"\n",
    "    if is_training:\n",
    "        # More aggressive augmentation for training set\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
    "                std=[0.229, 0.224, 0.225]     # ImageNet stds\n",
    "            )\n",
    "        ])\n",
    "    else:\n",
    "        # Simpler preprocessing for validation/inference\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(IMAGE_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# Create dataset class\n",
    "class HouseplantDataset(Dataset):\n",
    "    \"\"\"Dataset class for houseplant images.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None, class_names=None):\n",
    "        \"\"\"Initialize the dataset.\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # If there's actual data in the directory\n",
    "        if os.path.exists(data_dir) and len(os.listdir(data_dir)) > 0:\n",
    "            self.classes = sorted([d for d in os.listdir(data_dir) \n",
    "                             if os.path.isdir(os.path.join(data_dir, d))])\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "            self.samples = self._make_dataset()\n",
    "        # If we're just initializing with class names (for testing/demo)\n",
    "        elif class_names is not None:\n",
    "            self.classes = class_names\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "            self.samples = []  # Empty samples list\n",
    "        else:\n",
    "            # Fallback to empty lists\n",
    "            self.classes = []\n",
    "            self.class_to_idx = {}\n",
    "            self.samples = []\n",
    "    \n",
    "    def _make_dataset(self):\n",
    "        \"\"\"Create a list of (image_path, class_idx) tuples.\"\"\"\n",
    "        samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for root, _, files in os.walk(class_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        samples.append((os.path.join(root, file), class_idx))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset.\"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a sample from the dataset.\"\"\"\n",
    "        if len(self.samples) == 0:\n",
    "            # Create a dummy sample for testing/demo\n",
    "            dummy_tensor = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return dummy_tensor, 0\n",
    "        \n",
    "        image_path, class_idx = self.samples[idx]\n",
    "        \n",
    "        # Load and convert image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Apply transforms if available\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, class_idx\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a placeholder if image loading fails\n",
    "            placeholder = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return placeholder, class_idx\n",
    "    \n",
    "    def get_class_name(self, class_idx):\n",
    "        \"\"\"Get the class name for a given class index.\"\"\"\n",
    "        if class_idx < len(self.classes):\n",
    "            return self.classes[class_idx]\n",
    "        else:\n",
    "            return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we'll create a small dummy dataset for demonstration purposes. In a real scenario, you would download and prepare a real dataset with plant images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dummy dataset for demonstration\n",
    "# In a real scenario, you would download a real dataset\n",
    "\n",
    "# Function to download a sample image\n",
    "def download_sample_image(plant_name, save_dir=\"data/demo\"):\n",
    "    \"\"\"Download a sample image for a given plant species.\"\"\"\n",
    "    # Convert plant name to a search term\n",
    "    search_term = plant_name.replace(\" \", \"+\")\n",
    "    \n",
    "    # Create a placeholder image\n",
    "    img = Image.new('RGB', (300, 300), color=(73, 109, 137))\n",
    "    \n",
    "    # Save in the appropriate directory\n",
    "    os.makedirs(os.path.join(save_dir, plant_name.replace(\" \", \"_\")), exist_ok=True)\n",
    "    img_path = os.path.join(save_dir, plant_name.replace(\" \", \"_\"), f\"{plant_name.replace(' ', '_')}_sample.jpg\")\n",
    "    img.save(img_path)\n",
    "    \n",
    "    return img_path\n",
    "\n",
    "# Create a small dummy dataset\n",
    "demo_plants = COMMON_HOUSEPLANTS[:3]  # Just use the first 3 plants for demo\n",
    "demo_dir = \"data/demo\"\n",
    "os.makedirs(demo_dir, exist_ok=True)\n",
    "\n",
    "demo_images = []\n",
    "for plant in demo_plants:\n",
    "    img_path = download_sample_image(plant, demo_dir)\n",
    "    demo_images.append(img_path)\n",
    "\n",
    "print(f\"Created demo dataset with {len(demo_plants)} plant species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets\n",
    "train_transform = create_transforms(is_training=True)\n",
    "val_transform = create_transforms(is_training=False)\n",
    "\n",
    "# We'll use the demo dataset for both training and validation\n",
    "train_dataset = HouseplantDataset(demo_dir, transform=train_transform)\n",
    "val_dataset = HouseplantDataset(demo_dir, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 4  # Small batch size for demo\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created datasets with {len(train_dataset.classes)} classes\")\n",
    "print(f\"Class names: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development <a id=\"model\"></a>\n",
    "\n",
    "Now let's define our model for plant identification. We'll use transfer learning with a pre-trained MobileNetV3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, model_type=\"mobilenet\", pretrained=True):\n",
    "    \"\"\"Create a model for plant classification.\"\"\"\n",
    "    if model_type == \"mobilenet\":\n",
    "        # Load MobileNetV3 small for better efficiency\n",
    "        model = models.mobilenet_v3_small(pretrained=pretrained)\n",
    "        \n",
    "        # Modify classifier for our number of classes\n",
    "        in_features = model.classifier[3].in_features\n",
    "        model.classifier[3] = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    elif model_type == \"resnet\":\n",
    "        # Load ResNet-18 for a good balance of performance and speed\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Modify final fully connected layer for our number of classes\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    elif model_type == \"efficientnet\":\n",
    "        # Load EfficientNet B0 for a good balance\n",
    "        model = models.efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Modify classifier for our number of classes\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a model with our current classes\n",
    "model = create_model(len(train_dataset.classes), model_type=\"mobilenet\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Created {type(model).__name__} model with {len(train_dataset.classes)} output classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model <a id=\"training\"></a>\n",
    "\n",
    "Let's set up our training functions and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for inputs, targets in pbar:\n",
    "        # Move data to device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss / (pbar.n + 1),\n",
    "            'acc': 100. * correct / total if total > 0 else 0\n",
    "        })\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(dataloader) if len(dataloader) > 0 else 0\n",
    "    epoch_acc = 100. * correct / total if total > 0 else 0\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model on validation data.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store predictions and targets for detailed metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss = running_loss / len(dataloader) if len(dataloader) > 0 else 0\n",
    "    val_acc = 100. * correct / total if total > 0 else 0\n",
    "    \n",
    "    return val_loss, val_acc, all_preds, all_targets\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=5, learning_rate=0.001):\n",
    "    \"\"\"Train the model for a specified number of epochs.\"\"\"\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, all_preds, all_targets = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Save metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_acc': val_acc,\n",
    "                'train_acc': train_acc\n",
    "            }, \"models/best_model.pth\")\n",
    "            print(f\"Saved new best model with validation accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Calculate training time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Return metrics for plotting\n",
    "    return train_losses, val_losses, train_accs, val_accs, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with our dummy data\n",
    "# In a real scenario, you would train with a larger dataset\n",
    "# or use a pre-trained model\n",
    "\n",
    "# We'll just do a quick training run for demonstration\n",
    "if len(train_dataset.samples) > 0 and len(val_dataset.samples) > 0:\n",
    "    train_losses, val_losses, train_accs, val_accs, best_val_acc = train_model(\n",
    "        model, train_loader, val_loader, num_epochs=2, learning_rate=0.0001\n",
    "    )\n",
    "    \n",
    "    # Plotting training metrics\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Training Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping training due to empty dataset.\")\n",
    "    print(\"For a real implementation, use a proper dataset or a pre-trained model.\")\n",
    "    \n",
    "    # Save a dummy model for demonstration\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': 0,\n",
    "        'val_acc': 0.0,\n",
    "        'train_acc': 0.0\n",
    "    }, \"models/best_model.pth\")\n",
    "    \n",
    "    print(\"Saved a dummy model for demonstration purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Evaluation <a id=\"inference\"></a>\n",
    "\n",
    "Now let's implement functions to use our trained model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, size=IMAGE_SIZE):\n",
    "    \"\"\"Preprocess an image for inference.\"\"\"\n",
    "    # Create inference transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Load and transform image\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path\n",
    "        image = Image.open(image).convert('RGB')\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        # If image is a numpy array\n",
    "        image = Image.fromarray(image).convert('RGB')\n",
    "    \n",
    "    # Apply transform\n",
    "    image_tensor = transform(image)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "def identify_plant(model, image, class_names, top_k=3):\n",
    "    \"\"\"Identify a plant from an image.\"\"\"\n",
    "    # Preprocess the image\n",
    "    image_tensor = preprocess_image(image)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get top-k probabilities and indices\n",
    "        top_probs, top_indices = torch.topk(probabilities, min(top_k, len(class_names)))\n",
    "        \n",
    "        # Convert to lists\n",
    "        top_probs = top_probs.cpu().numpy()[0]\n",
    "        top_indices = top_indices.cpu().numpy()[0]\n",
    "    \n",
    "    # Create result list\n",
    "    results = []\n",
    "    for i, (idx, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "        if idx < len(class_names):\n",
    "            results.append({\n",
    "                'rank': i + 1,\n",
    "                'class_name': class_names[idx],\n",
    "                'probability': float(prob)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_plant_care_info(plant_name, care_database):\n",
    "    \"\"\"Get care information for a plant species.\"\"\"\n",
    "    # Look for exact match first\n",
    "    if plant_name in care_database:\n",
    "        return care_database[plant_name]\n",
    "    \n",
    "    # Try common name match\n",
    "    for scientific_name, info in care_database.items():\n",
    "        if info.get('common_name') == plant_name:\n",
    "            return info\n",
    "    \n",
    "    # Try case-insensitive partial match\n",
    "    plant_name_lower = plant_name.lower()\n",
    "    for scientific_name, info in care_database.items():\n",
    "        if (plant_name_lower in scientific_name.lower() or \n",
    "            plant_name_lower in info.get('common_name', '').lower()):\n",
    "            return info\n",
    "    \n",
    "    # No match found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for inference\n",
    "def load_model_for_inference(model_path, num_classes):\n",
    "    \"\"\"Load a trained model for inference.\"\"\"\n",
    "    # Create a new model\n",
    "    model = create_model(num_classes, model_type=\"mobilenet\")\n",
    "    \n",
    "    # Load saved state dict\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded model from {model_path} with validation accuracy: {checkpoint.get('val_acc', 0):.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Using uninitialized model instead.\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load our trained model\n",
    "inference_model = load_model_for_inference(\"models/best_model.pth\", len(train_dataset.classes))\n",
    "\n",
    "# For demonstration, we'll use the class names from the training dataset\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Load care database\n",
    "with open(\"data/care_database.json\", \"r\") as f:\n",
    "    care_database = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our inference functionality with a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with one of our demo images\n",
    "if len(demo_images) > 0:\n",
    "    test_image_path = demo_images[0]\n",
    "    \n",
    "    # Show the image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    img = Image.open(test_image_path).convert('RGB')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify the plant\n",
    "    results = identify_plant(inference_model, test_image_path, class_names)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nIdentification Results:\")\n",
    "    for result in results:\n",
    "        print(f\"{result['rank']}. {result['class_name']}: {result['probability']:.2%} confidence\")\n",
    "    \n",
    "    # Get care information for the top prediction\n",
    "    top_prediction = results[0]['class_name']\n",
    "    care_info = get_plant_care_info(top_prediction, care_database)\n",
    "    \n",
    "    if care_info:\n",
    "        print(\"\\nCare Information:\")\n",
    "        print(f\"Common name: {care_info.get('common_name', 'Unknown')}\")\n",
    "        print(f\"Light: {care_info.get('light', 'Unknown')}\")\n",
    "        print(f\"Water: {care_info.get('water', 'Unknown')}\")\n",
    "        print(f\"Temperature: {care_info.get('temperature', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"\\nNo care information available for this plant.\")\n",
    "else:\n",
    "    print(\"No demo images available for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Care Recommendations <a id=\"care\"></a>\n",
    "\n",
    "Let's implement a function to format care information for a better user experience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_care_info(care_info):\n",
    "    \"\"\"Format care information for display.\"\"\"\n",
    "    if not care_info:\n",
    "        return \"No care information available for this plant.\"\n",
    "    \n",
    "    common_name = care_info.get('common_name', 'Unknown')\n",
    "    \n",
    "    # Format care sections with icons\n",
    "    care_sections = [\n",
    "        ('light', 'Light Requirements', '☀️'),\n",
    "        ('water', 'Watering Needs', '💧'),\n",
    "        ('soil', 'Soil Type', '🌱'),\n",
    "        ('temperature', 'Temperature', '🌡️'),\n",
    "        ('humidity', 'Humidity', '💨'),\n",
    "        ('fertilizer', 'Fertilizer', '🧪'),\n",
    "        ('common_issues', 'Common Issues', '⚠️')\n",
    "    ]\n",
    "    \n",
    "    # Build the formatted output\n",
    "    output = f\"## {common_name} Care Guide\\n\\n\"\n",
    "    \n",
    "    for key, label, icon in care_sections:\n",
    "        if key in care_info and care_info[key]:\n",
    "            output += f\"### {icon} {label}\\n\"\n",
    "            output += f\"{care_info[key]}\\n\\n\"\n",
    "    \n",
    "    # Add toxicity warning if applicable\n",
    "    if 'toxicity' in care_info and care_info['toxicity']:\n",
    "        output += f\"### ⚠️ Toxicity\\n\"\n",
    "        output += f\"{care_info['toxicity']}\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Display formatted care information for a sample plant\n",
    "if \"Monstera deliciosa\" in care_database:\n",
    "    care_info = care_database[\"Monstera deliciosa\"]\n",
    "    formatted_care = format_care_info(care_info)\n",
    "    print(formatted_care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Interface with Gradio <a id=\"interface\"></a>\n",
    "\n",
    "Now, let's create an interactive interface using Gradio to make our plant identification assistant user-friendly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_get_care(image):\n",
    "    \"\"\"Identify a plant from an image and provide care information.\"\"\"\n",
    "    if image is None:\n",
    "        return \"Please upload an image\", \"\", 0\n",
    "    \n",
    "    # Identify the plant\n",
    "    results = identify_plant(inference_model, image, class_names)\n",
    "    \n",
    "    # Format the identification results\n",
    "    identification_html = \"<div style='padding: 10px; background-color: #f8f9fa; border-radius: 10px;'>\"\n",
    "    identification_html += \"<h3>Identification Results:</h3>\"\n",
    "    \n",
    "    # Add top prediction with larger styling\n",
    "    top_pred = results[0]\n",
    "    scientific_name = top_pred['class_name']\n",
    "    \n",
    "    # Try to get common name from care database\n",
    "    care_info = get_plant_care_info(scientific_name, care_database)\n",
    "    common_name = care_info.get('common_name', '') if care_info else ''\n",
    "    \n",
    "    name_display = f\"{scientific_name}\"\n",
    "    if common_name:\n",
    "        name_display += f\" <span style='font-style: italic;'>({common_name})</span>\"\n",
    "    \n",
    "    identification_html += f\"<div style='margin-bottom: 15px;'>\"\n",
    "    identification_html += f\"<p style='font-size: 18px; font-weight: bold;'>{name_display}</p>\"\n",
    "    identification_html += f\"<p>Confidence: {top_pred['probability']:.1%}</p>\"\n",
    "    identification_html += \"</div>\"\n",
    "    \n",
    "    # Add other predictions if there are any\n",
    "    if len(results) > 1:\n",
    "        identification_html += \"<div style='margin-top: 10px;'>\"\n",
    "        identification_html += \"<h4>Other possibilities:</h4>\"\n",
    "        identification_html += \"<ul>\"\n",
    "        \n",
    "        for pred in results[1:]:\n",
    "            # Try to get common name\n",
    "            pred_care = get_plant_care_info(pred['class_name'], care_database)\n",
    "            pred_common = pred_care.get('common_name', '') if pred_care else ''\n",
    "            \n",
    "            pred_display = f\"{pred['class_name']}\"\n",
    "            if pred_common:\n",
    "                pred_display += f\" <span style='font-style: italic;'>({pred_common})</span>\"\n",
    "                \n",
    "            identification_html += f\"<li>{pred_display} <span>({pred['probability']:.1%})</span></li>\"\n",
    "        \n",
    "        identification_html += \"</ul>\"\n",
    "        identification_html += \"</div>\"\n",
    "    \n",
    "    identification_html += \"</div>\"\n",
    "    \n",
    "    # Get and format care information\n",
    "    if care_info:\n",
    "        care_text = format_care_info(care_info)\n",
    "    else:\n",
    "        care_text = \"No care information available for this plant.\"\n",
    "    \n",
    "    # Return confidence as a percentage for the meter\n",
    "    confidence = float(top_pred['probability']) * 100\n",
    "    \n",
    "    return identification_html, care_text, confidence\n",
    "\n",
    "# Create the Gradio interface\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create a Gradio interface for the plant identification assistant.\"\"\"\n",
    "    # Title and description\n",
    "    title = \"Common Houseplant Identification Assistant\"\n",
    "    description = \"\"\"\n",
    "    Upload an image of your houseplant, and this tool will identify the species and provide care recommendations.\n",
    "    The model can recognize common houseplant species and provide detailed care instructions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # CSS for styling\n",
    "    css = \"\"\"\n",
    "    .gradio-container {max-width: 900px;}\n",
    "    h1 {text-align: center; color: #2e7d32;}\n",
    "    .confidence-meter {height: 25px; border-radius: 5px; overflow: hidden;}\n",
    "    .confidence-meter .bar {height: 100%; background-color: #4caf50;}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the interface\n",
    "    with gr.Blocks(css=css) as interface:\n",
    "        gr.Markdown(f\"<h1>{title}</h1>\")\n",
    "        gr.Markdown(description)\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # Input components\n",
    "                input_image = gr.Image(\n",
    "                    type=\"pil\",\n",
    "                    label=\"Upload or take a photo of your houseplant\"\n",
    "                )\n",
    "                identify_button = gr.Button(\"Identify Plant\", variant=\"primary\")\n",
    "                \n",
    "            with gr.Column(scale=1):\n",
    "                # Output components\n",
    "                confidence_meter = gr.Number(\n",
    "                    label=\"Confidence (%)\", \n",
    "                    value=0,\n",
    "                    interactive=False\n",
    "                )\n",
    "                identification_result = gr.HTML(\n",
    "                    label=\"Identification Results\",\n",
    "                    value=\"Upload an image and click 'Identify Plant' to get results.\"\n",
    "                )\n",
    "                care_info = gr.Markdown(\n",
    "                    label=\"Care Information\",\n",
    "                    value=\"Plant care information will appear here after identification.\"\n",
    "                )\n",
    "        \n",
    "        # Set up the action\n",
    "        identify_button.click(\n",
    "            fn=identify_and_get_care,\n",
    "            inputs=[input_image],\n",
    "            outputs=[identification_result, care_info, confidence_meter]\n",
    "        )\n",
    "        \n",
    "        # Footer info\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### Tips for Best Results\n",
    "        \n",
    "        - Take photos in natural light\n",
    "        - Capture both leaves and overall plant structure\n",
    "        - Avoid blurry or poorly lit images\n",
    "        - For more accurate identification, try multiple angles\n",
    "        \n",
    "        This tool works best with common houseplants. If your plant isn't identified correctly, \n",
    "        consider consulting a plant specialist or reference book.\n",
    "        \"\"\")\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and launch the interface\n",
    "interface = create_gradio_interface()\n",
    "interface.launch(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've implemented a complete plant identification assistant in this Jupyter notebook. This notebook includes:\n",
    "\n",
    "1. Data preparation and loading\n",
    "2. Model creation using transfer learning\n",
    "3. Training and evaluation functions\n",
    "4. Plant identification and care recommendation features\n",
    "5. An interactive Gradio interface\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To create a full-featured application, you could:\n",
    "\n",
    "1. **Collect a larger dataset**: Gather more plant images for better accuracy\n",
    "2. **Train with more epochs**: Run training for longer to improve the model\n",
    "3. **Expand the care database**: Add more plant species and detailed care information\n",
    "4. **Add plant health analysis**: Extend the model to detect common plant diseases\n",
    "5. **Deploy the application**: Export and deploy as a web service or mobile app\n",
    "\n",
    "This notebook provides a solid foundation that you can build upon to create a practical tool for plant enthusiasts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Houseplant Identification Assistant with PlantNet\n",
    "\n",
    "This notebook implements a machine learning-based application that helps identify common houseplants from images and provides basic care recommendations. We'll be using a pre-trained PlantNet model for improved accuracy.\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Data Preparation](#data)\n",
    "3. [PlantNet Model Integration](#plantnet)\n",
    "4. [Model Fine-tuning](#fine-tuning)\n",
    "5. [Inference and Evaluation](#inference)\n",
    "6. [Care Recommendations](#care)\n",
    "7. [Interactive Interface with Gradio](#interface)\n",
    "\n",
    "Let's begin by setting up our environment and installing the necessary dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation <a id=\"setup\"></a>\n",
    "\n",
    "First, we'll install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision tqdm numpy matplotlib pandas pillow gradio scikit-learn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gradio as gr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation <a id=\"data\"></a>\n",
    "\n",
    "We'll now define our dataset of common houseplants. For the purposes of this notebook, we'll create a database with information about 20 common houseplant species and their care requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of common houseplant species\n",
    "COMMON_HOUSEPLANTS = [\n",
    "    \"Monstera deliciosa\",        # Swiss Cheese Plant\n",
    "    \"Ficus lyrata\",              # Fiddle Leaf Fig\n",
    "    \"Sansevieria trifasciata\",   # Snake Plant\n",
    "    \"Chlorophytum comosum\",      # Spider Plant\n",
    "    \"Epipremnum aureum\",         # Pothos\n",
    "    \"Spathiphyllum wallisii\",    # Peace Lily\n",
    "    \"Zamioculcas zamiifolia\",    # ZZ Plant\n",
    "    \"Dracaena marginata\",        # Dragon Tree\n",
    "    \"Calathea makoyana\",         # Peacock Plant\n",
    "    \"Pilea peperomioides\",       # Chinese Money Plant\n",
    "    \"Philodendron bipinnatifidum\", # Split-leaf Philodendron\n",
    "    \"Aloe vera\",                 # Aloe Vera\n",
    "    \"Ficus elastica\",            # Rubber Plant\n",
    "    \"Maranta leuconeura\",        # Prayer Plant\n",
    "    \"Aglaonema commutatum\",      # Chinese Evergreen\n",
    "    \"Peperomia obtusifolia\",     # Baby Rubber Plant\n",
    "    \"Anthurium andraeanum\",      # Flamingo Flower\n",
    "    \"Schlumbergera bridgesii\",   # Christmas Cactus\n",
    "    \"Crassula ovata\",            # Jade Plant\n",
    "    \"Aspidistra elatior\"         # Cast Iron Plant\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create care information database\n",
    "care_database = {\n",
    "  \"Monstera deliciosa\": {\n",
    "    \"common_name\": \"Swiss Cheese Plant\",\n",
    "    \"light\": \"Bright indirect light. Avoid direct sunlight which can burn the leaves.\",\n",
    "    \"water\": \"Allow top 2-3 inches of soil to dry out between waterings. Water less in winter.\",\n",
    "    \"soil\": \"Well-draining potting mix with some peat and perlite.\",\n",
    "    \"temperature\": \"65-85°F (18-29°C). Keep away from cold drafts.\",\n",
    "    \"humidity\": \"Prefers moderate to high humidity. Regular misting is beneficial.\",\n",
    "    \"fertilizer\": \"Feed monthly during growing season with balanced houseplant fertilizer.\",\n",
    "    \"common_issues\": \"Brown leaf tips (low humidity), yellow leaves (overwatering), lack of fenestration (insufficient light).\",\n",
    "    \"toxicity\": \"Toxic to pets if ingested. Contains calcium oxalate crystals.\"\n",
    "  },\n",
    "  \"Ficus lyrata\": {\n",
    "    \"common_name\": \"Fiddle Leaf Fig\",\n",
    "    \"light\": \"Bright indirect light. Some direct morning sun is beneficial.\",\n",
    "    \"water\": \"Water when top inch of soil is dry. Ensure thorough drainage.\",\n",
    "    \"soil\": \"Well-draining potting mix with peat and perlite.\",\n",
    "    \"temperature\": \"60-75°F (15-24°C). Avoid temperature fluctuations.\",\n",
    "    \"humidity\": \"Moderate humidity, around 40-60%.\",\n",
    "    \"fertilizer\": \"Feed monthly in spring and summer with diluted houseplant fertilizer.\",\n",
    "    \"common_issues\": \"Brown spots (overwatering or bacterial infection), leaf drop (stress from relocation or temperature changes).\",\n",
    "    \"toxicity\": \"Mildly toxic to pets and humans if ingested.\"\n",
    "  },\n",
    "  \"Sansevieria trifasciata\": {\n",
    "    \"common_name\": \"Snake Plant\",\n",
    "    \"light\": \"Adaptable to various light conditions from low light to bright indirect light.\",\n",
    "    \"water\": \"Allow soil to dry completely between waterings. Water sparingly in winter.\",\n",
    "    \"soil\": \"Well-draining, sandy soil mix.\",\n",
    "    \"temperature\": \"55-85°F (13-29°C). Can tolerate temperature fluctuations.\",\n",
    "    \"humidity\": \"Adaptable to various humidity levels, including dry air.\",\n",
    "    \"fertilizer\": \"Feed sparingly with cactus fertilizer during growing season.\",\n",
    "    \"common_issues\": \"Root rot (overwatering), brown tips (fluoride in water).\",\n",
    "    \"toxicity\": \"Mildly toxic to pets if ingested.\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Add more plants to the care database\n",
    "care_database[\"Chlorophytum comosum\"] = {\n",
    "    \"common_name\": \"Spider Plant\",\n",
    "    \"light\": \"Bright indirect light. Can tolerate lower light conditions.\",\n",
    "    \"water\": \"Keep soil moderately moist. Allow top to dry slightly between waterings.\",\n",
    "    \"soil\": \"Well-draining potting mix.\",\n",
    "    \"temperature\": \"60-75°F (15-24°C).\",\n",
    "    \"humidity\": \"Prefers moderate humidity but tolerates dry air.\",\n",
    "    \"fertilizer\": \"Feed monthly during growing season with balanced fertilizer.\",\n",
    "    \"common_issues\": \"Brown tips (fluoride in water, dry air), pale leaves (too much light).\",\n",
    "    \"toxicity\": \"Non-toxic to pets and humans.\"\n",
    "}\n",
    "\n",
    "care_database[\"Epipremnum aureum\"] = {\n",
    "    \"common_name\": \"Pothos\",\n",
    "    \"light\": \"Adaptable to various light conditions. Prefers moderate indirect light.\",\n",
    "    \"water\": \"Allow top inch of soil to dry between waterings.\",\n",
    "    \"soil\": \"Standard potting mix with good drainage.\",\n",
    "    \"temperature\": \"65-85°F (18-29°C).\",\n",
    "    \"humidity\": \"Adaptable to normal household humidity.\",\n",
    "    \"fertilizer\": \"Feed monthly with balanced houseplant fertilizer.\",\n",
    "    \"common_issues\": \"Yellow leaves (overwatering), leggy growth (insufficient light).\",\n",
    "    \"toxicity\": \"Toxic to pets if ingested. Contains calcium oxalate crystals.\"\n",
    "}\n",
    "\n",
    "# Save the care database to a JSON file\n",
    "with open(\"data/care_database.json\", \"w\") as f:\n",
    "    json.dump(care_database, f, indent=2)\n",
    "\n",
    "print(f\"Created care database with {len(care_database)} plant species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n",
    "\n",
    "Now, let's define our dataset class for loading and preprocessing plant images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and transformations\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# Create transformations optimized for PlantNet\n",
    "def get_plantnet_transforms():\n",
    "    \"\"\"Get the transforms that match PlantNet's preprocessing.\"\"\"\n",
    "    \n",
    "    # PlantNet typically uses these preprocessing steps\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    return data_transforms\n",
    "\n",
    "# Create dataset class\n",
    "class HouseplantDataset(Dataset):\n",
    "    \"\"\"Dataset class for houseplant images.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None, class_names=None):\n",
    "        \"\"\"Initialize the dataset.\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # If there's actual data in the directory\n",
    "        if os.path.exists(data_dir) and len(os.listdir(data_dir)) > 0:\n",
    "            self.classes = sorted([d for d in os.listdir(data_dir) \n",
    "                             if os.path.isdir(os.path.join(data_dir, d))])\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "            self.samples = self._make_dataset()\n",
    "        # If we're just initializing with class names (for testing/demo)\n",
    "        elif class_names is not None:\n",
    "            self.classes = class_names\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "            self.samples = []  # Empty samples list\n",
    "        else:\n",
    "            # Fallback to empty lists\n",
    "            self.classes = []\n",
    "            self.class_to_idx = {}\n",
    "            self.samples = []\n",
    "    \n",
    "    def _make_dataset(self):\n",
    "        \"\"\"Create a list of (image_path, class_idx) tuples.\"\"\"\n",
    "        samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            for root, _, files in os.walk(class_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        samples.append((os.path.join(root, file), class_idx))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset.\"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a sample from the dataset.\"\"\"\n",
    "        if len(self.samples) == 0:\n",
    "            # Create a dummy sample for testing/demo\n",
    "            dummy_tensor = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return dummy_tensor, 0\n",
    "        \n",
    "        image_path, class_idx = self.samples[idx]\n",
    "        \n",
    "        # Load and convert image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Apply transforms if available\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, class_idx\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a placeholder if image loading fails\n",
    "            placeholder = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "            return placeholder, class_idx\n",
    "    \n",
    "    def get_class_name(self, class_idx):\n",
    "        \"\"\"Get the class name for a given class index.\"\"\"\n",
    "        if class_idx < len(self.classes):\n",
    "            return self.classes[class_idx]\n",
    "        else:\n",
    "            return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, let's create a small dummy dataset for demonstration purposes. In a real scenario, you would download and prepare a real dataset with plant images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dummy dataset for demonstration\n",
    "# In a real scenario, you would download a real dataset\n",
    "\n",
    "# Function to download a sample image\n",
    "def download_sample_image(plant_name, save_dir=\"data/demo\"):\n",
    "    \"\"\"Create a placeholder image for a given plant species.\"\"\"\n",
    "    # Create a placeholder image\n",
    "    img = Image.new('RGB', (300, 300), color=(73, 109, 137))\n",
    "    \n",
    "    # Save in the appropriate directory\n",
    "    os.makedirs(os.path.join(save_dir, plant_name.replace(\" \", \"_\")), exist_ok=True)\n",
    "    img_path = os.path.join(save_dir, plant_name.replace(\" \", \"_\"), f\"{plant_name.replace(' ', '_')}_sample.jpg\")\n",
    "    img.save(img_path)\n",
    "    \n",
    "    return img_path\n",
    "\n",
    "# Create a small dummy dataset\n",
    "demo_plants = COMMON_HOUSEPLANTS[:5]  # Just use the first 5 plants for demo\n",
    "demo_dir = \"data/demo\"\n",
    "os.makedirs(demo_dir, exist_ok=True)\n",
    "\n",
    "demo_images = []\n",
    "for plant in demo_plants:\n",
    "    img_path = download_sample_image(plant, demo_dir)\n",
    "    demo_images.append(img_path)\n",
    "\n",
    "print(f\"Created demo dataset with {len(demo_plants)} plant species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PlantNet Model Integration <a id=\"plantnet\"></a>\n",
    "\n",
    "Now, let's integrate the pre-trained PlantNet model for improved plant identification. PlantNet has been trained on a large dataset of plant images and will provide better accuracy than training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_plantnet_weights(url, save_path):\n",
    "    \"\"\"\n",
    "    Download PlantNet pre-trained weights if they don't exist locally.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to download the weights from\n",
    "        save_path (str): Path to save the weights file\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the weights file\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    from tqdm.notebook import tqdm\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"PlantNet weights already exist at {save_path}\")\n",
    "        return save_path\n",
    "    \n",
    "    # File doesn't exist, download it\n",
    "    print(f\"Downloading PlantNet weights to {save_path}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(save_path, 'wb') as file, tqdm(\n",
    "        desc=os.path.basename(save_path),\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "    \n",
    "    print(\"Download complete!\")\n",
    "    return save_path\n",
    "\n",
    "def load_plantnet_model(weights_path, num_classes=1081, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Load the PlantNet pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        weights_path (str): Path to the pre-trained weights\n",
    "        num_classes (int): Number of classes in the pre-trained model\n",
    "        use_gpu (bool): Whether to load the model on GPU\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: Loaded model\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from torchvision.models import resnet18\n",
    "    \n",
    "    # Create the model architecture\n",
    "    model = resnet18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    # Load the weights\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        checkpoint = torch.load(weights_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    # Load state dict from checkpoint\n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Remove 'module.' prefix if present (from DataParallel)\n",
    "    if list(state_dict.keys())[0].startswith('module.'):\n",
    "        state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Move model to GPU if requested\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    model.eval()  # Set to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to download and load the PlantNet pre-trained model. Note that for demonstration purposes, we'll simulate this since the actual weights file might be quite large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally, we would download the actual PlantNet weights from their site\n",
    "# For this notebook, we'll simulate it by creating a dummy weights file\n",
    "\n",
    "def create_dummy_weights_file():\n",
    "    \"\"\"Create a dummy weights file for demonstration.\"\"\"\n",
    "    # Create a dummy ResNet18 model\n",
    "    dummy_model = models.resnet18(pretrained=True)\n",
    "    dummy_model.fc = nn.Linear(dummy_model.fc.in_features, 1081)  # PlantNet has 1081 classes\n",
    "    \n",
    "    # Save the model\n",
    "    os.makedirs('models/plantnet', exist_ok=True)\n",
    "    weights_path = 'models/plantnet/resnet18_weights_best_acc.tar'\n",
    "    torch.save({\n",
    "        'state_dict': dummy_model.state_dict(),\n",
    "        'epoch': 100,\n",
    "        'best_acc': 0.85\n",
    "    }, weights_path)\n",
    "    \n",
    "    return weights_path\n",
    "\n",
    "# Create dummy weights file for demonstration\n",
    "weights_path = create_dummy_weights_file()\n",
    "print(f\"Created dummy PlantNet weights file at {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PlantNet model\n",
    "plantnet_model = load_plantnet_model(\n",
    "    weights_path=weights_path,\n",
    "    num_classes=1081,  # PlantNet has 1081 classes\n",
    "    use_gpu=(device.type == 'cuda')\n",
    ")\n",
    "\n",
    "print(f\"Loaded PlantNet model: {type(plantnet_model).__name__}\")\n",
    "print(f\"Output layer: {plantnet_model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's adapt the PlantNet model for our specific task of identifying common houseplants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_plantnet_model(plantnet_model, target_classes, device):\n",
    "    \"\"\"\n",
    "    Adapt the PlantNet pre-trained model for our specific plant classes.\n",
    "    \n",
    "    Args:\n",
    "        plantnet_model: The pre-trained PlantNet model\n",
    "        target_classes (list): List of our target class names\n",
    "        device: Device to load the model on\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: Adapted model\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    \n",
    "    # Freeze all parameters to use the feature extraction part as is\n",
    "    for param in plantnet_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    num_ftrs = plantnet_model.fc.in_features\n",
    "    plantnet_model.fc = nn.Linear(num_ftrs, len(target_classes))\n",
    "    \n",
    "    # Move model to the appropriate device\n",
    "    plantnet_model = plantnet_model.to(device)\n",
    "    \n",
    "    return plantnet_model\n",
    "\n",
    "# Adapt the PlantNet model for our houseplant classes\n",
    "adapted_model = adapt_plantnet_model(\n",
    "    plantnet_model=plantnet_model,\n",
    "    target_classes=COMMON_HOUSEPLANTS,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Adapted PlantNet model for {len(COMMON_HOUSEPLANTS)} houseplant classes\")\n",
    "print(f\"New output layer: {adapted_model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Fine-tuning <a id=\"fine-tuning\"></a>\n",
    "\n",
    "Now that we have adapted the PlantNet model for our specific classes, let's fine-tune it on our dataset. Since we're using transfer learning, we'll only need to train the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, train_loader, val_loader, num_epochs=5, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Fine-tune the adapted PlantNet model on our dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: The adapted PlantNet model\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for the optimizer\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained model, training metrics)\n",
    "    \"\"\"\n",
    "    # Only train the final layer\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_update.append(param)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params_to_update, lr=learning_rate)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "    print(f\"Training {len(params_to_update)} parameters\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(train_loader, desc=\"Training\")\n",
    "        \n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (pbar.n + 1),\n",
    "                'acc': 100. * correct / total if total > 0 else 0\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss = running_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        train_acc = 100. * correct / total if total > 0 else 0\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_loss = val_running_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "        val_acc = 100. * val_correct / val_total if val_total > 0 else 0\n",
    "        \n",
    "        # Save metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_acc': val_acc,\n",
    "                'train_acc': train_acc\n",
    "            }, \"models/best_plantnet_adapted.pth\")\n",
    "            print(f\"Saved new best model with validation accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"Fine-tuning completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Return metrics for plotting\n",
    "    return model, (train_losses, val_losses, train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets with PlantNet transforms\n",
    "transforms_dict = get_plantnet_transforms()\n",
    "train_transform = transforms_dict['train']\n",
    "val_transform = transforms_dict['val']\n",
    "\n",
    "# We'll use the demo dataset for both training and validation\n",
    "train_dataset = HouseplantDataset(demo_dir, transform=train_transform)\n",
    "val_dataset = HouseplantDataset(demo_dir, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 4  # Small batch size for demo\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created datasets with {len(train_dataset.classes)} classes\")\n",
    "print(f\"Class names: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "if len(train_dataset.samples) > 0 and len(val_dataset.samples) > 0:\n",
    "    finetuned_model, metrics = fine_tune_model(\n",
    "        model=adapted_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=2,  # Just 2 epochs for demonstration\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    train_losses, val_losses, train_accs, val_accs = metrics\n",
    "    \n",
    "    # Plotting training metrics\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Training Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping fine-tuning due to empty dataset.\")\n",
    "    print(\"For a real implementation, you would use a proper dataset.\")\n",
    "    \n",
    "    # Save the adapted model for demonstration\n",
    "    torch.save({\n",
    "        'model_state_dict': adapted_model.state_dict(),\n",
    "        'epoch': 0,\n",
    "        'val_acc': 0.0,\n",
    "        'train_acc': 0.0\n",
    "    }, \"models/best_plantnet_adapted.pth\")\n",
    "    \n",
    "    print(\"Saved the adapted model for demonstration purposes.\")\n",
    "    finetuned_model = adapted_model  # Just use the adapted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Evaluation <a id=\"inference\"></a>\n",
    "\n",
    "Now let's implement functions to use our fine-tuned PlantNet model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_plant_with_plantnet(model, image, class_names, device, top_k=3):\n",
    "    \"\"\"\n",
    "    Identify a plant using the PlantNet model.\n",
    "    \n",
    "    Args:\n",
    "        model: The PlantNet model\n",
    "        image: PIL Image or path to image\n",
    "        class_names: List of class names\n",
    "        device: Device to run inference on\n",
    "        top_k: Number of top predictions to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Top predictions\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Ensure model is in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the image\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load image if it's a path\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image).convert('RGB')\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image).convert('RGB')\n",
    "    \n",
    "    # Preprocess and add batch dimension\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get top-k probabilities and indices\n",
    "        top_probs, top_indices = torch.topk(probabilities, min(top_k, len(class_names)))\n",
    "        \n",
    "        # Convert to lists\n",
    "        top_probs = top_probs.cpu().numpy()[0]\n",
    "        top_indices = top_indices.cpu().numpy()[0]\n",
    "    \n",
    "    # Create result list\n",
    "    results = []\n",
    "    for i, (idx, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "        if idx < len(class_names):\n",
    "            results.append({\n",
    "                'rank': i + 1,\n",
    "                'class_name': class_names[idx],\n",
    "                'probability': float(prob)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_plant_care_info(plant_name, care_database):\n",
    "    \"\"\"Get care information for a plant species.\"\"\"\n",
    "    # Look for exact match first\n",
    "    if plant_name in care_database:\n",
    "        return care_database[plant_name]\n",
    "    \n",
    "    # Try common name match\n",
    "    for scientific_name, info in care_database.items():\n",
    "        if info.get('common_name') == plant_name:\n",
    "            return info\n",
    "    \n",
    "    # Try case-insensitive partial match\n",
    "    plant_name_lower = plant_name.lower()\n",
    "    for scientific_name, info in care_database.items():\n",
    "        if (plant_name_lower in scientific_name.lower() or \n",
    "            plant_name_lower in info.get('common_name', '').lower()):\n",
    "            return info\n",
    "    \n",
    "    # No match found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our plant identification with a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with one of our demo images\n",
    "if len(demo_images) > 0:\n",
    "    test_image_path = demo_images[0]\n",
    "    \n",
    "    # Show the image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    img = Image.open(test_image_path).convert('RGB')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify the plant\n",
    "    results = identify_plant_with_plantnet(finetuned_model, test_image_path, COMMON_HOUSEPLANTS, device)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nIdentification Results:\")\n",
    "    for result in results:\n",
    "        print(f\"{result['rank']}. {result['class_name']}: {result['probability']:.2%} confidence\")\n",
    "    \n",
    "    # Get care information for the top prediction\n",
    "    top_prediction = results[0]['class_name']\n",
    "    care_info = get_plant_care_info(top_prediction, care_database)\n",
    "    \n",
    "    if care_info:\n",
    "        print(\"\\nCare Information:\")\n",
    "        print(f\"Common name: {care_info.get('common_name', 'Unknown')}\")\n",
    "        print(f\"Light: {care_info.get('light', 'Unknown')}\")\n",
    "        print(f\"Water: {care_info.get('water', 'Unknown')}\")\n",
    "        print(f\"Temperature: {care_info.get('temperature', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"\\nNo care information available for this plant.\")\n",
    "else:\n",
    "    print(\"No demo images available for testing.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
